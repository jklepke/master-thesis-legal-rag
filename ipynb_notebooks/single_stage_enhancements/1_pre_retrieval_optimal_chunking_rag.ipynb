{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1aa3c7d",
   "metadata": {},
   "source": [
    "# Implementation, Testing and Evaluation for Optimal Chunking in RAG\n",
    "\n",
    "#### Notebook Outline\n",
    "1. Imports and Configurations\n",
    "2. Creation of Vector Database\n",
    "3. Querying the Vector Database\n",
    "4. Output of RAG Experiments\n",
    "5. Evaluations\n",
    "\n",
    "This notebook uses functions from the Baseline RAG .ipynb file and adapts these."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaeef42",
   "metadata": {},
   "source": [
    "### 1. Imports and Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71794701",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af35d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Standard Library Imports ===\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import uuid\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# === Scientific and Utility Libraries ===\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# === Environment Management ===\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# === OpenAI and Tokenization ===\n",
    "import openai\n",
    "\n",
    "# === LangChain Community Integrations ===\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# === Project Root Configuration ===\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# === Custom Project Modules ===\n",
    "from ipynb_notebooks.baseline.rag_utils.baseline_rag import (\n",
    "    generate_data_store,\n",
    "    enrich_eval_dataset_with_rag_responses,\n",
    "    clean_text,\n",
    "    save_to_chroma,\n",
    "    save_documents_for_sparse_retrieval\n",
    ")\n",
    "\n",
    "from ipynb_notebooks.evaluation_datasets.retrieval_eval.eval_vector_dataset_generator import generate_evalset\n",
    "from ipynb_notebooks.evaluation_datasets.retrieval_eval.retrieval_metrics import run_retrieval_evaluation\n",
    "from ipynb_notebooks.evaluation_datasets.generation_eval.generation_metrics import run_generation_evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5693599e",
   "metadata": {},
   "source": [
    "Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6dba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables. Assumes that the project directory contains a .env file with API keys\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key from the environment variables\n",
    "# Make sure to update \"OPENAI_API_KEY\" to match the variable name in your .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# Define constants for paths\n",
    "DATA_PATH = \"../../data/laws_and_ordinances.json\"  # Directory containing the url to the law and ordinance documents\n",
    "DATA_PATH_SHORT_VERSION = \"../../data/laws_and_ordinances_short_version.json\" # Directory containing a subset of all urls for testing purposes\n",
    "CHROMA_PATH = \"chroma_dbs/chroma\"  # Directory to save the Chroma vector store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd00c15",
   "metadata": {},
   "source": [
    "### 2. Creation of Vector Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360ce362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate chroma vector databases with different chunk sizes and overlaps\n",
    "chunk_configurations = [\n",
    "    (128, 0),\n",
    "    (128, 16),\n",
    "    (256, 0),\n",
    "    (256, 32),\n",
    "    (512, 0),\n",
    "    (512, 64),\n",
    "    (1024, 0),\n",
    "    (1024, 128),  \n",
    "    (2048, 0),\n",
    "    (2048, 256)\n",
    "]\n",
    "\n",
    "chroma_dbs = {}\n",
    "\n",
    "for size, overlap in chunk_configurations:\n",
    "    key = f\"chroma_{size}_{overlap}\"\n",
    "    chroma_dbs[key] = generate_data_store(\n",
    "        datapath=\"../../data/laws_and_ordinances.json\",\n",
    "        chunk_size=size,\n",
    "        chunk_overlap=overlap,\n",
    "        optimization=\"optimal_chunking\"\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1d920f",
   "metadata": {},
   "source": [
    "#### 2.1 Special Case of Dynamic Chunking\n",
    "\n",
    "Here, the creation of a chroma vector database is adapted so that the legal texts and regulations are not split according to fixed chunk sizes, but the entire paragraphs of a law are vectorized. The aim is to investigate whether the correctness and factual accuracy of the model can be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d23761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_paragraph_documents(datapath: str):\n",
    "    # Load JSON file\n",
    "    with open(datapath, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    documents = []\n",
    "    chunk_index = 1  # Track chunk index globally\n",
    "\n",
    "    for category in [\"laws\", \"ordinances\"]:\n",
    "        entries = data.get(category, [])\n",
    "        for entry in tqdm(entries, desc=f\"→ Processing {category}\"):\n",
    "            title = entry.get(\"title\", \"Unknown Title\")\n",
    "            paragraphs = entry.get(\"paragraphs\", [])\n",
    "\n",
    "            for para in tqdm(paragraphs, desc=f\"  ↳ Paragraphs in '{title}'\", leave=False):\n",
    "                para_url = para.get(\"paragraph_url\", \"\")\n",
    "                para_name = para.get(\"paragraph_name\", \"Unknown Paragraph\")\n",
    "\n",
    "                if para_url:\n",
    "                    try:\n",
    "                        # Load content from paragraph URL\n",
    "                        loader = WebBaseLoader(para_url)\n",
    "                        docs = loader.load()\n",
    "\n",
    "                        for doc in docs:\n",
    "                            raw_content = doc.page_content\n",
    "                            cleaned_content = clean_text(raw_content)\n",
    "                            doc.page_content = cleaned_content\n",
    "\n",
    "                            doc.metadata.update({\n",
    "                                \"law_title\": title,\n",
    "                                \"category\": category,\n",
    "                                \"paragraph_id\": para.get(\"paragraph_ID\"),\n",
    "                                \"paragraph_name\": para_name,\n",
    "                                \"paragraph_url\": para_url,\n",
    "                                \"chunk_id\": str(uuid.uuid4()),\n",
    "                                \"chunk_index\": chunk_index,\n",
    "                            })\n",
    "\n",
    "                            documents.append(doc)\n",
    "                            chunk_index += 1\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading paragraph from URL {para_url}: {e}\")\n",
    "                else:\n",
    "                    print(f\"No paragraph URL found for {title}\")\n",
    "\n",
    "    if not documents:\n",
    "        raise ValueError(\"No paragraph documents could be loaded from the input.\")\n",
    "\n",
    "    print(f\"Successfully loaded {len(documents)} paragraph-level documents.\")\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10808c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_store_from_paragraphs(datapath: str, chunk_size: str = \"paragraph_wise_chunking\", chunk_overlap: str = \"no_overlap\", baseline: bool = False, optimization: str = \"default\"):\n",
    "    documents = load_paragraph_documents(datapath)\n",
    "    save_documents_for_sparse_retrieval(documents, chunk_size, chunk_overlap, optimization, baseline)\n",
    "    chroma_path = save_to_chroma(documents, chunk_size=\"_dynamic\", chunk_overlap=0, baseline=baseline, optimization=optimization)\n",
    "    return chroma_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfec9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_dbs[\"chroma_paragraph_wise_chunking\"] = generate_data_store_from_paragraphs(\n",
    "        datapath=\"../../data/laws_and_ordinances.json\",\n",
    "        optimization=\"optimal_chunking\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f5c8a2",
   "metadata": {},
   "source": [
    "### 3. Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae3890a",
   "metadata": {},
   "source": [
    "#### 3.1 Generate Evaluation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9449dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_sets = {}\n",
    "\n",
    "for key, db in chroma_dbs.items():\n",
    "    print(f\"Erzeuge Testset für {key}...\")\n",
    "    eval_sets[key] = generate_evalset(\n",
    "        chroma_db=db,\n",
    "        test_set_size=50,\n",
    "        optimization=\"1_optimal_chunking/\",\n",
    "        query_distribution={\n",
    "            \"single\": 0.6,\n",
    "            \"multi_specific\": 0.2,\n",
    "            \"multi_intra_document\": 0.2\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79195505",
   "metadata": {},
   "source": [
    "#### 3.2 Enrich Evaluation Datasets with Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce07ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_eval_datasets = {}\n",
    "\n",
    "for key, chroma_path in chroma_dbs.items():\n",
    "    \n",
    "    print(f\"Enriching dataset '{eval_sets[key]}' using Chroma index: {key}...\")\n",
    "\n",
    "    enriched_eval_datasets[key] = enrich_eval_dataset_with_rag_responses(\n",
    "        eval_dataset=eval_sets[key],\n",
    "        chroma_path=chroma_path,\n",
    "        model_name=\"gpt-4o-mini\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e293a7ea",
   "metadata": {},
   "source": [
    "#### 3.3. Evaluate Retrieval & Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6399a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results_optimal_chunking = {}\n",
    "generation_results_optimal_chunking = {}\n",
    "\n",
    "for key, chroma_path in chroma_dbs.items():\n",
    "    db_name = chroma_path.split(\"/\")[-1]\n",
    "    \n",
    "    json_filename = f\"1_optimal_chunking/artificial_evaluation_dataset_for_{db_name}_rag_enriched.json\"\n",
    "    model_name = f\"optimal_chunking_rag_{key.split('_')[1]}_{key.split('_')[2]}_{db_name.split('_')[3]}\"\n",
    "    \n",
    "    print(f\"Evaluating {model_name} using dataset {json_filename}...\")\n",
    "    \n",
    "    retrieval_result = run_retrieval_evaluation(\n",
    "        json_filename=json_filename,\n",
    "        model_name=model_name\n",
    "    )\n",
    "    \n",
    "    generation_result = run_generation_evaluation(\n",
    "        json_filename=json_filename,\n",
    "        model_name=model_name\n",
    "    )\n",
    "    \n",
    "    evaluation_results_optimal_chunking[model_name] = retrieval_result\n",
    "    generation_results_optimal_chunking[model_name] = generation_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63ec415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Leere Liste für die Einträge\n",
    "rows = []\n",
    "\n",
    "# Alle Modelle iterieren\n",
    "for model_name in evaluation_results_optimal_chunking.keys():\n",
    "    # Hol die Retrieval- und Generationsergebnisse\n",
    "    retrieval = evaluation_results_optimal_chunking[model_name]\n",
    "    generation = generation_results_optimal_chunking[model_name]\n",
    "\n",
    "    # Kombiniere beide in ein Dictionary und füge den Modellnamen hinzu\n",
    "    combined = {\n",
    "        \"model\": model_name,\n",
    "        **retrieval,\n",
    "        **generation\n",
    "    }\n",
    "\n",
    "    # Füge zur Liste hinzu\n",
    "    rows.append(combined)\n",
    "\n",
    "# Erstelle DataFrame\n",
    "results_df = pd.DataFrame(rows)\n",
    "\n",
    "results_df.to_csv(\"combined_evaluation_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0aea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chunksize_and_overlap(filename):\n",
    "    \n",
    "    basename = os.path.basename(filename)\n",
    "    # Search for rag_<chunksize>_<overlap>\n",
    "    match = re.search(r'rag_(\\d+)_(\\d+)', basename)\n",
    "    if match:\n",
    "        chunksize = int(match.group(1))\n",
    "        overlap = int(match.group(2))\n",
    "        return (chunksize, overlap)\n",
    "    else:\n",
    "        return (float('inf'), float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a263fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "folder_path = \"eval_results/1_optimal_chunking\"\n",
    "pattern_retrieval = os.path.join(folder_path, \"optimal_chunking*retrieval_evaluation.csv\")\n",
    "pattern_generation = os.path.join(folder_path, \"optimal_chunking*generation_evaluation.csv\")\n",
    "csv_retrieval_files = glob.glob(pattern_retrieval)\n",
    "csv_generation_files = glob.glob(pattern_generation)\n",
    "\n",
    "# Sort files\n",
    "csv_retrieval_files_sorted = sorted(csv_retrieval_files, key=extract_chunksize_and_overlap)\n",
    "csv_generation_files_sorted = sorted(csv_generation_files, key=extract_chunksize_and_overlap)\n",
    "\n",
    "#for f in csv_files_sorted:\n",
    "#    chunksize, overlap = extract_chunksize_and_overlap(f)\n",
    "\n",
    "df_retrieval = []\n",
    "df_generation = []\n",
    "\n",
    "for f in csv_retrieval_files_sorted:\n",
    "    df = pd.read_csv(f)\n",
    "    chunksize, overlap = extract_chunksize_and_overlap(f)\n",
    "    df_retrieval.append(df)\n",
    "    \n",
    "for f in csv_generation_files_sorted:\n",
    "    df = pd.read_csv(f)\n",
    "    chunksize, overlap = extract_chunksize_and_overlap(f)\n",
    "    df_generation.append(df)\n",
    "\n",
    "combined_df_retrieval = pd.concat(df_retrieval, ignore_index=True)\n",
    "combined_df_generation = pd.concat(df_generation, ignore_index=True)\n",
    "\n",
    "output_path_retrieval = os.path.join(folder_path, \"combined_optimal_chunking_retrieval_evaluation.csv\")\n",
    "combined_df_retrieval.to_csv(output_path_retrieval, index=False)\n",
    "output_path_generation = os.path.join(folder_path, \"combined_optimal_chunking_generation_evaluation.csv\")\n",
    "combined_df_generation.to_csv(output_path_generation, index=False)\n",
    "\n",
    "print(f\"Done! Retrieval stored in {output_path_retrieval} & Generation Evaluation in {output_path_generation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d24f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_results_optimal_chunking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
